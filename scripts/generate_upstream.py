import requests
from datetime import datetime
from urllib.parse import urlparse
import os

# DNS é…ç½®ï¼ˆè…¾è®¯/é˜¿é‡Œ DoHï¼Œå­—èŠ‚ IPï¼‰
#TENCENT_DNS = '119.29.29.29 119.28.28.28'
TENCENT_DNS = 'https://doh.pub/dns-query'
BYTEDANCE_DNS = '180.184.1.1 180.184.2.2'
#ALIBABA_DNS = '223.5.5.5 223.6.6.6'
ALIBABA_DNS = 'https://dns.alidns.com/dns-query'

# æ–°æºåœ°å€ï¼ˆMetaCubeX æ›´å…¨æ›´æ´»è·ƒï½ï¼‰
SOURCE_URLS = {
    'tencent': 'https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/refs/heads/meta/geo/geosite/tencent.list',
    'bytedance': 'https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/refs/heads/meta/geo/geosite/bytedance.list',
    'alibaba': 'https://raw.githubusercontent.com/MetaCubeX/meta-rules-dat/refs/heads/meta/geo/geosite/alibaba.list'
}

CATEGORIES = {
    'tencent': ('è…¾è®¯ç³»', TENCENT_DNS),
    'bytedance': ('å­—èŠ‚ç³»', BYTEDANCE_DNS),
    'alibaba': ('é˜¿é‡Œç³»', ALIBABA_DNS)
}

def get_root_domain(domain):
    """æå–æ ¹åŸŸåï¼ˆäºŒçº§åŸŸåï¼Œå¦‚ sub.qq.com â†’ qq.comï¼‰"""
    parts = domain.split('.')
    if len(parts) <= 2:
        return domain
    return '.'.join(parts[-2:])  # ç®€å•å¤„ç†ï¼Œå‡è®¾å¸¸è§ .com/.cn ç­‰

def fetch_domains(url):
    try:
        response = requests.get(url, timeout=30)
        response.raise_for_status()
    except Exception as e:
        print(f"ä¸‹è½½ {url} å¤±è´¥: {e}")
        return set()
    
    root_domains = set()
    for line in response.text.splitlines():
        line = line.strip()
        if not line or line.startswith('#'):
            continue
        # ç›´æ¥å–åŸŸåï¼ˆMetaCubeX åˆ—è¡¨æ˜¯çº¯åŸŸåï¼‰
        domain = line.lower()
        if domain and '.' in domain:
            root = get_root_domain(domain)
            root_domains.add(root)
    
    return root_domains

def update_readme(stats, total_domains, all_lines_count, update_time):
    """æ›´æ–° README.md æ–‡ä»¶ä¸­çš„ç»Ÿè®¡ä¿¡æ¯"""
    readme_content = f"""# AdGuardHome Upstream DNS é¡¹ç›®

è‡ªåŠ¨ç”Ÿæˆå›½å†…ä¸‰å¤§äº’è”ç½‘å…¬å¸çš„ä¸“ç”¨ DNS ä¸Šæ¸¸é…ç½®ï¼Œä¼˜åŒ–å›½å†…ç½‘ç«™è®¿é—®é€Ÿåº¦ã€‚

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- **æœ€åæ›´æ–°æ—¶é—´**: {update_time}
- **æ€»æ ¹åŸŸåæ•°é‡**: {total_domains}
- **æ€» upstream æ¡ç›®**: {all_lines_count}
- **è…¾è®¯ç³»åŸŸåæ•°é‡**: {stats.get('tencent', 0)}
- **å­—èŠ‚ç³»åŸŸåæ•°é‡**: {stats.get('bytedance', 0)}
- **é˜¿é‡Œç³»åŸŸåæ•°é‡**: {stats.get('alibaba', 0)}

## ğŸš€ ä½¿ç”¨æ–¹æ³•

1. ä¸‹è½½ `upstream_dns.txt` æ–‡ä»¶
2. åœ¨ AdGuard Home çš„ã€Œè®¾ç½®ã€â†’ã€ŒDNS è®¾ç½®ã€â†’ã€Œä¸Šæ¸¸ DNS æœåŠ¡å™¨ã€ä¸­ç²˜è´´å†…å®¹
3. åœ¨ä¸» Upstream æœ€ä¸‹é¢æ·»åŠ å…œåº• DNSï¼š`202.98.0.68`

## ğŸ”„ è‡ªåŠ¨æ›´æ–°

æœ¬é¡¹ç›®æ¯ 3 å¤©è‡ªåŠ¨æ›´æ–°ä¸€æ¬¡åŸŸååˆ—è¡¨ï¼Œç¡®ä¿æ•°æ®æœ€æ–°ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

- `upstream_dns.txt`: ç”Ÿæˆçš„ AdGuardHome ä¸Šæ¸¸ DNS é…ç½®
- `scripts/generate_upstream.py`: ç”Ÿæˆè„šæœ¬
- `.github/workflows/generate.yml`: GitHub Actions å·¥ä½œæµ

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼
"""

    with open('README.md', 'w', encoding='utf-8') as f:
        f.write(readme_content)
    
    print("README.md ç»Ÿè®¡ä¿¡æ¯å·²æ›´æ–°ï¼")

print("å¼€å§‹ä» MetaCubeX ä¸‹è½½ä¸‰å¤§å…¬å¸æ ¹åŸŸååˆ—è¡¨ï¼ˆå»é‡æ•´åˆï¼‰...")
company_domains = {}
total_domains = 0
stats = {}

for cat, (name, _) in CATEGORIES.items():
    url = SOURCE_URLS[cat]
    domains = fetch_domains(url)
    company_domains[cat] = domains
    count = len(domains)
    total_domains += count
    stats[cat] = count
    print(f"{name} æ ¹åŸŸåæ•°é‡: {count}")

update_time = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')

def generate_upstream_lines(domains, dns_server, max_per_line=50):
    lines = []
    domain_list = sorted(domains)
    for i in range(0, len(domain_list), max_per_line):
        group = domain_list[i:i + max_per_line]
        domain_str = '/' + '/'.join(group) + '/'
        lines.append(f'[{domain_str}]{dns_server}')
    return lines

output_lines = [
    "# AdGuardHome Upstream DNS æ–‡ä»¶ - è‡ªåŠ¨ç”Ÿæˆï¼ˆMetaCubeX æº + æ ¹åŸŸåæ•´åˆï¼‰",
    f"# æ›´æ–°æ—¶é—´: {update_time}",
    f"# è…¾è®¯ç³»æ ¹åŸŸå: {stats.get('tencent', 0)} â†’ DoH {TENCENT_DNS}",
    f"# å­—èŠ‚ç³»æ ¹åŸŸå: {stats.get('bytedance', 0)} â†’ IP {BYTEDANCE_DNS}",
    f"# é˜¿é‡Œç³»æ ¹åŸŸå: {stats.get('alibaba', 0)} â†’ DoH {ALIBABA_DNS}",
    f"# å…œåº•è¯´æ˜: è¯·åœ¨ AdGuard Home ä¸» Upstream æœ€ä¸‹é¢åŠ  202.98.0.68",
    f"# æ€»æ ¹åŸŸåæ•°é‡: {total_domains}",
    f"# æ€» upstream æ¡ç›®: 0ï¼ˆä¸‹æ–¹è®¡ç®—ï¼‰",
    ""
]

all_lines_count = 0
for cat, (_, dns) in CATEGORIES.items():
    if company_domains[cat]:
        lines = generate_upstream_lines(company_domains[cat], dns)
        all_lines_count += len(lines)
        output_lines.extend(lines)
        output_lines.append("")

output_lines[7] = f"# æ€» upstream æ¡ç›®: {all_lines_count}"

# ç”Ÿæˆ upstream_dns.txt
with open('upstream_dns.txt', 'w', encoding='utf-8') as f:
    f.write('\n'.join(output_lines) + '\n')

# æ›´æ–° README.md ç»Ÿè®¡ä¿¡æ¯
update_readme(stats, total_domains, all_lines_count, update_time)

print(f"ç”ŸæˆæˆåŠŸï¼MetaCubeX æºæ›´å…¨ï¼Œå…± {total_domains} ä¸ªæ ¹åŸŸåï¼Œ{all_lines_count} æ¡è§„åˆ™ï½")
print(f"README.md å·²æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼šæœ€åæ›´æ–° {update_time}")
